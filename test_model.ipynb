{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tflite-runtime in /home/andrews/.local/lib/python3.8/site-packages (2.13.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/andrews/.local/lib/python3.8/site-packages (from tflite-runtime) (1.24.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tflite-runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "video_path_nurse = \"./NURSE.mp4\"\n",
    "video_path_taste_good = \"./TASTE GOOD.mp4\"\n",
    "video_path_cloudy = \"./CLOUDS, cloudy, cloud.mp4\"\n",
    "video_path_swim = \"./swim.mp4\"\n",
    "\n",
    "\n",
    "\n",
    "#Testing\n",
    "\n",
    "video_path_face = \"./Test/face.mp4\"\n",
    "cap = cv2.VideoCapture(video_path_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1) as face_mesh, \\\n",
    "     mp_hands.Hands(static_image_mode=False, max_num_hands=2) as hands, \\\n",
    "     mp_pose.Pose(static_image_mode=False) as pose:\n",
    "    frame_number = 0\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the BGR image to RGB for Mediapipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process face landmarks\n",
    "        results_face = face_mesh.process(image_rgb)\n",
    "        if results_face.multi_face_landmarks:\n",
    "            face_landmarks = results_face.multi_face_landmarks[0]\n",
    "            for idx, landmark in enumerate(face_landmarks.landmark):\n",
    "                data_list.append([frame_number, f\"{frame_number}-face-{idx}\", \"face\", idx, landmark.x, landmark.y, landmark.z])\n",
    "\n",
    "        # Process hand landmarks\n",
    "        results_hands = hands.process(image_rgb)\n",
    "        if results_hands.multi_hand_landmarks:\n",
    "            for hand_landmarks in results_hands.multi_hand_landmarks:\n",
    "                for idx, landmark in enumerate(hand_landmarks.landmark):\n",
    "                    data_list.append([frame_number, f\"{frame_number}-right_hand-{idx}\", \"right-hand\",  idx, landmark.x, landmark.y, landmark.z])\n",
    "                    mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        else:\n",
    "    # If no hand landmarks were found, add placeholder data with NaN values\n",
    "            for idx in range(21):  # Assuming there are 21 hand landmarks in total\n",
    "                data_list.append([frame_number, f\"{frame_number}-right_hand-{idx}\", \"right-hand\", idx, float('NaN'), float('NaN'), float('NaN')])\n",
    "\n",
    "        \n",
    "        results_pose = pose.process(image_rgb)\n",
    "        if results_pose.pose_landmarks:\n",
    "            pose_landmarks = results_pose.pose_landmarks.landmark\n",
    "            for idx, landmark in enumerate(pose_landmarks):\n",
    "                data_list.append([frame_number, f\"{frame_number}-pose-{idx}\", \"pose\", idx, landmark.x, landmark.y, landmark.z])\n",
    "\n",
    "        # Draw the landmarks on the frame (optional)\n",
    "        mp_drawing.draw_landmarks(image, face_landmarks, mp_face_mesh.FACEMESH_CONTOURS)\n",
    "        mp_drawing.draw_landmarks(image, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "\n",
    "        # Display the frame (optional)\n",
    "        cv2.imshow('MediaPipe', image)\n",
    "        frame_number += 1\n",
    "\n",
    "        # Press 'q' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_list, columns=[\"frame\", \"row_id\", \"type\", \"landmark_index\", \"x\", \"y\", \"z\"])\n",
    "df.to_parquet(\"extracted_features.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_parquet('./1006440534.parquet')\n",
    "test_data_kaggle = pd.read_parquet('1001373962.parquet')\n",
    "test_data_my_own = pd.read_parquet('extracted_features.parquet')\n",
    "# test_data_my_own['frame'] = test_data_my_own['frame'].astype('int16')\n",
    "# test_data_my_own['landmark_index'] = test_data_my_own['landmark_index'].astype('int16')\n",
    "# test_data_my_own.head()\n",
    "# test_data['frame'].unique()\n",
    "# test_data.info()\n",
    "# test_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_my_own['frame'].unique())\n",
    "len(test_data['frame'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_relevant_data_subset(pq_path, num_frames):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    \n",
    "    # Calculate the number of landmarks per frame\n",
    "    rows_per_frame = len(data) // num_frames\n",
    "\n",
    "    # Adjust the number of frames if needed (to account for rounding errors)\n",
    "    num_frames = len(data) // rows_per_frame\n",
    "    \n",
    "    # Reshape the data into a 3D array\n",
    "    data = data.values[:num_frames * rows_per_frame].reshape(num_frames, rows_per_frame, len(data_columns))\n",
    "    \n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# demo_raw_data = load_relevant_data_subset('./1006440534.parquet', ROWS_PER_FRAME=543)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# demo_raw_data = load_relevant_data_subset('./extracted_features.parquet', 93, 150, 3)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m demo_raw_data \u001b[39m=\u001b[39m load_relevant_data_subset(\u001b[39m'\u001b[39;49m\u001b[39m./extracted_features.parquet\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mlen\u001b[39;49m(test_data_my_own[\u001b[39m'\u001b[39;49m\u001b[39mframe\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49munique()))\n",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m, in \u001b[0;36mload_relevant_data_subset\u001b[0;34m(pq_path, num_frames)\u001b[0m\n\u001b[1;32m      3\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_parquet(pq_path, columns\u001b[39m=\u001b[39mdata_columns)\n\u001b[1;32m      5\u001b[0m \u001b[39m# Calculate the number of landmarks per frame\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m rows_per_frame \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39;49m(data) \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m num_frames\n\u001b[1;32m      8\u001b[0m \u001b[39m# Adjust the number of frames if needed (to account for rounding errors)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m num_frames \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m rows_per_frame\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "# demo_raw_data = load_relevant_data_subset('./1006440534.parquet', ROWS_PER_FRAME=543)\n",
    "# demo_raw_data = load_relevant_data_subset('./extracted_features.parquet', 93, 150, 3)\n",
    "\n",
    "demo_raw_data = load_relevant_data_subset('./extracted_features.parquet', len(test_data_my_own['frame'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 522, 3)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORD2SIGN = {206: 'sticky',\n",
    " 20: 'before',\n",
    " 178: 'pretty',\n",
    " 114: 'hen',\n",
    " 221: 'tomorrow',\n",
    " 230: 'up',\n",
    " 25: 'blow',\n",
    " 236: 'weus',\n",
    " 184: 'read',\n",
    " 191: 'say',\n",
    " 248: 'zebra',\n",
    " 189: 'sad',\n",
    " 62: 'drawer',\n",
    " 5: 'animal',\n",
    " 167: 'pen',\n",
    " 60: 'donkey',\n",
    " 41: 'cheek',\n",
    " 51: 'cowboy',\n",
    " 192: 'scissors',\n",
    " 181: 'quiet',\n",
    " 63: 'drink',\n",
    " 94: 'girl',\n",
    " 200: 'sleepy',\n",
    " 249: 'zipper',\n",
    " 171: 'pig',\n",
    " 13: 'bad',\n",
    " 9: 'arm',\n",
    " 61: 'down',\n",
    " 123: 'if',\n",
    " 240: 'why',\n",
    " 166: 'pajamas',\n",
    " 203: 'snow',\n",
    " 137: 'loud',\n",
    " 195: 'shirt',\n",
    " 31: 'brown',\n",
    " 146: 'moon',\n",
    " 23: 'bird',\n",
    " 210: 'sun',\n",
    " 76: 'fast',\n",
    " 1: 'after',\n",
    " 54: 'cute',\n",
    " 77: 'feet',\n",
    " 4: 'alligator',\n",
    " 87: 'food',\n",
    " 113: 'hello',\n",
    " 93: 'giraffe',\n",
    " 180: 'puzzle',\n",
    " 211: 'table',\n",
    " 132: 'like',\n",
    " 153: 'no',\n",
    " 122: 'icecream',\n",
    " 67: 'duck',\n",
    " 69: 'elephant',\n",
    " 141: 'many',\n",
    " 18: 'bedroom',\n",
    " 205: 'stay',\n",
    " 74: 'fall',\n",
    " 246: 'yourself',\n",
    " 183: 'rain',\n",
    " 135: 'listen',\n",
    " 44: 'chocolate',\n",
    " 124: 'into',\n",
    " 11: 'awake',\n",
    " 40: 'chair',\n",
    " 7: 'any',\n",
    " 155: 'nose',\n",
    " 118: 'home',\n",
    " 161: 'open',\n",
    " 58: 'dog',\n",
    " 50: 'cow',\n",
    " 241: 'will',\n",
    " 149: 'mouth',\n",
    " 177: 'pretend',\n",
    " 172: 'pizza',\n",
    " 75: 'farm',\n",
    " 163: 'outside',\n",
    " 234: 'water',\n",
    " 81: 'finish',\n",
    " 159: 'old',\n",
    " 121: 'hungry',\n",
    " 112: 'helicopter',\n",
    " 130: 'lamp',\n",
    " 222: 'tongue',\n",
    " 194: 'shhh',\n",
    " 6: 'another',\n",
    " 103: 'gum',\n",
    " 214: 'thankyou',\n",
    " 128: 'kiss',\n",
    " 101: 'grass',\n",
    " 64: 'drop',\n",
    " 157: 'now',\n",
    " 233: 'wake',\n",
    " 116: 'hide',\n",
    " 201: 'smile',\n",
    " 226: 'toy',\n",
    " 216: 'there',\n",
    " 147: 'morning',\n",
    " 10: 'aunt',\n",
    " 102: 'green',\n",
    " 36: 'car',\n",
    " 213: 'taste',\n",
    " 39: 'cereal',\n",
    " 207: 'store',\n",
    " 66: 'dryer',\n",
    " 162: 'orange',\n",
    " 218: 'thirsty',\n",
    " 83: 'first',\n",
    " 45: 'clean',\n",
    " 3: 'all',\n",
    " 198: 'sick',\n",
    " 129: 'kitty',\n",
    " 96: 'glasswindow',\n",
    " 202: 'snack',\n",
    " 150: 'nap',\n",
    " 53: 'cut',\n",
    " 73: 'face',\n",
    " 99: 'grandma',\n",
    " 209: 'stuck',\n",
    " 91: 'garbage',\n",
    " 115: 'hesheit',\n",
    " 95: 'give',\n",
    " 104: 'hair',\n",
    " 125: 'jacket',\n",
    " 165: 'owl',\n",
    " 82: 'fireman',\n",
    " 227: 'tree',\n",
    " 16: 'because',\n",
    " 17: 'bed',\n",
    " 30: 'brother',\n",
    " 143: 'minemy',\n",
    " 127: 'jump',\n",
    " 245: 'yesterday',\n",
    " 145: 'mom',\n",
    " 111: 'hear',\n",
    " 174: 'police',\n",
    " 223: 'tooth',\n",
    " 212: 'talk',\n",
    " 224: 'toothbrush',\n",
    " 164: 'owie',\n",
    " 47: 'closet',\n",
    " 169: 'penny',\n",
    " 24: 'black',\n",
    " 85: 'flag',\n",
    " 238: 'white',\n",
    " 134: 'lips',\n",
    " 231: 'vacuum',\n",
    " 8: 'apple',\n",
    " 105: 'happy',\n",
    " 151: 'napkin',\n",
    " 92: 'gift',\n",
    " 70: 'empty',\n",
    " 46: 'close',\n",
    " 52: 'cry',\n",
    " 138: 'mad',\n",
    " 49: 'clown',\n",
    " 204: 'stairs',\n",
    " 42: 'child',\n",
    " 173: 'please',\n",
    " 65: 'dry',\n",
    " 72: 'eye',\n",
    " 235: 'wet',\n",
    " 32: 'bug',\n",
    " 109: 'haveto',\n",
    " 228: 'uncle',\n",
    " 199: 'sleep',\n",
    " 176: 'potty',\n",
    " 29: 'boy',\n",
    " 136: 'look',\n",
    " 107: 'hate',\n",
    " 71: 'every',\n",
    " 12: 'backyard',\n",
    " 22: 'better',\n",
    " 84: 'fish',\n",
    " 56: 'dance',\n",
    " 139: 'make',\n",
    " 98: 'goose',\n",
    " 38: 'cat',\n",
    " 232: 'wait',\n",
    " 14: 'balloon',\n",
    " 247: 'yucky',\n",
    " 2: 'airplane',\n",
    " 88: 'for',\n",
    " 126: 'jeans',\n",
    " 154: 'noisy',\n",
    " 142: 'milk',\n",
    " 239: 'who',\n",
    " 90: 'frog',\n",
    " 35: 'can',\n",
    " 215: 'that',\n",
    " 117: 'high',\n",
    " 244: 'yes',\n",
    " 196: 'shoe',\n",
    " 108: 'have',\n",
    " 48: 'cloud',\n",
    " 170: 'person',\n",
    " 187: 'ride',\n",
    " 34: 'callonphone',\n",
    " 37: 'carrot',\n",
    " 100: 'grandpa',\n",
    " 120: 'hot',\n",
    " 131: 'later',\n",
    " 229: 'underwear',\n",
    " 0: 'TV',\n",
    " 140: 'man',\n",
    " 217: 'think',\n",
    " 220: 'time',\n",
    " 80: 'finger',\n",
    " 86: 'flower',\n",
    " 15: 'bath',\n",
    " 28: 'book',\n",
    " 193: 'see',\n",
    " 208: 'story',\n",
    " 26: 'blue',\n",
    " 78: 'find',\n",
    " 148: 'mouse',\n",
    " 79: 'fine',\n",
    " 179: 'puppy',\n",
    " 55: 'dad',\n",
    " 21: 'beside',\n",
    " 225: 'touch',\n",
    " 89: 'frenchfries',\n",
    " 188: 'room',\n",
    " 19: 'bee',\n",
    " 27: 'boat',\n",
    " 156: 'not',\n",
    " 59: 'doll',\n",
    " 97: 'go',\n",
    " 190: 'same',\n",
    " 144: 'mitten',\n",
    " 160: 'on',\n",
    " 57: 'dirty',\n",
    " 182: 'radio',\n",
    " 197: 'shower',\n",
    " 186: 'refrigerator',\n",
    " 158: 'nuts',\n",
    " 175: 'pool',\n",
    " 242: 'wolf',\n",
    " 243: 'yellow',\n",
    " 110: 'head',\n",
    " 237: 'where',\n",
    " 33: 'bye',\n",
    " 133: 'lion',\n",
    " 152: 'night',\n",
    " 106: 'hat',\n",
    " 43: 'chin',\n",
    " 68: 'ear',\n",
    " 168: 'pencil',\n",
    " 119: 'horse',\n",
    " 219: 'tiger',\n",
    " 185: 'red'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED :  clown [49]\n"
     ]
    }
   ],
   "source": [
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "interpreter = tflite.Interpreter(\"./model.tflite\")\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "\n",
    "demo_raw_data_batched = np.expand_dims(demo_raw_data, axis=0)\n",
    "\n",
    "demo_raw_data_resized = np.resize(demo_raw_data_batched, (1, 543, 3))\n",
    "\n",
    "\n",
    "prediction_fn(inputs=demo_raw_data_resized)\n",
    "\n",
    "\n",
    "output = prediction_fn(inputs=demo_raw_data_resized)\n",
    "sign = output['outputs'].argmax()\n",
    "print(\"PRED : \", ORD2SIGN.get(sign), f'[{sign}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
